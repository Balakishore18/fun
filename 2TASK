from azure.cosmos import CosmosClient, PartitionKey, exceptions
import os

# Initialize Cosmos Client (use your actual endpoint and key)
url = os.environ['COSMOS_DB_ENDPOINT']
key = os.environ['COSMOS_DB_KEY']
client = CosmosClient(url, credential=key)

# Define your database and container names
metadata_db_name = 'your_metadata_database'
timestamps_container_name = 'your_timestamps_container'
jobs_db_name = 'your_jobs_database'
jobs_container_name = 'your_jobs_container'

# Get the container clients
timestamps_container_client = client.get_database_client(metadata_db_name).get_container_client(timestamps_container_name)
jobs_container_client = client.get_database_client(jobs_db_name).get_container_client(jobs_container_name)

# Function to get the last processed timestamp
def get_last_processed_timestamp():
    query = "SELECT TOP 1 c.last_processed_timestamp FROM c ORDER BY c.last_processed_timestamp DESC"
    items = list(timestamps_container_client.query_items(query=query, enable_cross_partition_query=True))
    return items[0]['last_processed_timestamp'] if items else 0

# Function to update the last processed timestamp
def update_last_processed_timestamp(timestamp):
    # For simplicity, assume there's only one timestamp document
    # If your logic requires multiple, you'll need to modify this code
    items = list(timestamps_container_client.query_items(
        query="SELECT * FROM c",
        enable_cross_partition_query=True))
    
    if items:
        # Update the existing document
        item = items[0]
        item['last_processed_timestamp'] = timestamp
        timestamps_container_client.replace_item(item=item, body=item)
    else:
        # Create a new document if it doesn't exist
        new_item = {'id': 'timestamp_tracker', 'last_processed_timestamp': timestamp}
        timestamps_container_client.create_item(body=new_item)

# Function to create jobs for the items
def create_jobs_for_items(items):
    # Placeholder for your job creation logic
    pass

# Main logic for incremental load
last_timestamp = get_last_processed_timestamp()

# Get all items from the jobs container that have a timestamp greater than last_timestamp
query = f"SELECT * FROM c WHERE c.timestamp > {last_timestamp}"
items_to_process = list(jobs_container_client.query_items(query=query, enable_cross_partition_query=True))

# Process each item to create a job
create_jobs_for_items(items_to_process)

# After processing, update the last processed timestamp
if items_to_process:
    # Assume the timestamp is a property of each item
    latest_timestamp = max(item['timestamp'] for item in items_to_process)
    update_last_processed_timestamp(latest_timestamp)
