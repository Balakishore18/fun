from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from datetime import datetime
import requests
from azure.cosmos import CosmosClient, PartitionKey
import json

# --- Cosmos DB Configuration (Fill these with your details) ---
cosmos_url = 'YOUR_COSMOS_DB_URL'
cosmos_key = 'YOUR_COSMOS_DB_KEY'
cosmos_database_name = 'YOUR_DATABASE_NAME'
cosmos_container_name = 'YOUR_CONTAINER_NAME'
client = CosmosClient(cosmos_url, credential=cosmos_key)
database = client.create_database_if_not_exists(id=cosmos_database_name)
container = database.create_container_if_not_exists(
    id=cosmos_container_name, 
    partition_key=PartitionKey(path="/id"),
    offer_throughput=400
)

# --- Functions for Airflow Tasks ---
def get_dag_id_from_cosmos_db():
    # Implement function to retrieve DAG ID from Cosmos DB
    pass

def job_1(**kwargs):
    # Implement the first job
    pass

def job_2(**kwargs):
    # Implement the second job, dependent on the first
    pass

def upsert_dag_details_to_cosmos_db(**kwargs):
    # Implement function to upsert DAG details into Cosmos DB
    pass

def generate_dag_graph(**kwargs):
    # Implement function to generate DAG graph
    pass

# --- DAG Definition ---
default_args = {
    'owner': 'airflow',
    'start_date': datetime(2023, 1, 1),
}

dag = DAG(
    dag_id='dynamic_dag',
    default_args=default_args,
    schedule_interval='@daily'
)

# Task to get DAG ID from Cosmos DB
get_dag_id_task = PythonOperator(
    task_id='get_dag_id',
    python_callable=get_dag_id_from_cosmos_db,
    dag=dag
)

# First job in the workflow
job_1_task = PythonOperator(
    task_id='job_1',
    python_callable=job_1,
    dag=dag
)

# Second job in the workflow, dependent on the first
job_2_task = PythonOperator(
    task_id='job_2',
    python_callable=job_2,
    dag=dag
)

# Task to upsert DAG details into Cosmos DB
upsert_dag_details_task = PythonOperator(
    task_id='upsert_dag_details',
    python_callable=upsert_dag_details_to_cosmos_db,
    dag=dag
)

# Task to generate DAG graph
generate_dag_graph_task = PythonOperator(
    task_id='generate_dag_graph',
    python_callable=generate_dag_graph,
    dag=dag
)

# Setting up Dependencies





from flask import Flask, jsonify, request
from azure.cosmos import CosmosClient, PartitionKey, exceptions
from graphviz import Digraph
import base64
from io import BytesIO

app = Flask(__name__)

# Cosmos DB configuration
cosmos_url = 'YOUR_COSMOS_DB_URL'
cosmos_key = 'YOUR_COSMOS_DB_KEY'
cosmos_database_name = 'YOUR_DATABASE_NAME'
cosmos_container_name = 'YOUR_CONTAINER_NAME'
client = CosmosClient(cosmos_url, credential=cosmos_key)
database = client.get_database_client(cosmos_database_name)
container = database.get_container_client(cosmos_container_name)

# Function to get DAG details from Cosmos DB
def get_dag_details(dag_id):
    query = "SELECT * FROM c WHERE c.dag_id = @dag_id"
    parameters = [{"name": "@dag_id", "value": dag_id}]
    try:
        items = list(container.query_items(
            query=query,
            parameters=parameters,
            enable_cross_partition_query=True
        ))
        return items[0] if items else None
    except exceptions.CosmosHttpResponseError as e:
        print(f'An error occurred: {e.message}')
        return None

# Function to generate and return the DAG graph in base64 encoding
def generate_and_return_dag_graph(dag_details):
    # Create a new directed graph
    dot = Digraph(comment='DAG')

    # Placeholder: Add your logic here to add nodes and edges from the dag_details
    # For example:
    # for node in dag_details['nodes']:
    #     dot.node(node)
    # for edge in dag_details['edges']:
    #     dot.edge(edge['start'], edge['end'])

    # Save the graph to a BytesIO object in PNG format
    png_image = BytesIO()
    dot.format = 'png'
    dot.render(png_image)
    png_image.seek(0)

    # Encode the image data to base64
    encoded_image = base64.b64encode(png_image.read()).decode('utf-8')
    return encoded_image

# API endpoint to get the DAG graph
@app.route('/dag_graph', methods=['GET'])
def dag_graph():
    dag_id = request.args.get('dag_id')
    if not dag_id:
        return jsonify({"error": "DAG ID is required"}), 400

    dag_details = get_dag_details(dag_id)
    if not dag_details:
        return jsonify({"error": "DAG not found"}), 404

    # Generate the graph image from the DAG details
    encoded_image = generate_and_return_dag_graph(dag_details)
    return jsonify({"graph_image_data": encoded_image})

if __name__ == '__main__':
    app.run(debug=True)

get_dag_id_task >> job_1_task >> job_2_task >> [upsert_dag_details_task, generate_dag_graph_task]




import streamlit as st
import requests
import base64
from PIL import Image
from io import BytesIO

st.title('DAG Viewer')

# The URL of your Flask API
API_URL = 'http://localhost:5000/dag_graph'

dag_id = st.text_input('Enter DAG ID')

if st.button('Show DAG Graph'):
    # Make a GET request to the Flask API to retrieve the graph
    response = requests.get(f"{API_URL}?dag_id={dag_id}")
    
    # If the response is successful, extract the graph image data
    if response.status_code == 200:
        data = response.json()
        graph_image_data = data['graph_image_data']
        
        # Decode the base64 image data
        decoded_image = base64.b64decode(graph_image_data)
        
        # Convert the binary data to an image
        image = Image.open(BytesIO(decoded_image))
        
        # Display the image in Streamlit
        st.image(image, use_column_width=True)
    else:
        # If the request failed, show an error message
        st.error('Failed to retrieve the DAG graph.')





from fastapi import FastAPI, HTTPException
from azure.cosmos import CosmosClient, exceptions
from pydantic import BaseModel
from typing import List, Optional
import uuid
from datetime import datetime

app = FastAPI()

# Cosmos DB configuration
COSMOS_DB_URL = 'your_cosmos_db_url'
COSMOS_DB_KEY = 'your_cosmos_db_key'
COSMOS_DB_DATABASE_NAME = 'your_database_name'
COSMOS_DB_CONTAINER_NAME = 'your_container_name'

# Initialize Cosmos DB client
client = CosmosClient(COSMOS_DB_URL, credential=COSMOS_DB_KEY)
database = client.get_database_client(COSMOS_DB_DATABASE_NAME)
container = database.get_container_client(COSMOS_DB_CONTAINER_NAME)

class TaskStatus(BaseModel):
    task_id: str
    state: str
    duration: Optional[int]
    operator: Optional[str]
    start_time: Optional[datetime]
    end_time: Optional[datetime]

class DagStatus(BaseModel):
    dag_id: str
    status: str
    timestamp: datetime = datetime.utcnow()
    run_id: Optional[str] = None
    execution_date: Optional[datetime] = None
    duration: Optional[int] = None
    state: Optional[str] = None
    tasks: Optional[List[TaskStatus]] = []
    errors: Optional[List[str]] = []
    user: Optional[str] = None
    tags: Optional[List[str]] = []
    notes: Optional[str] = None

@app.post('/store_dag_status')
def store_dag_status(dag_status: DagStatus):
    # Automatically generate a unique ID and run ID if not provided
    document_id = str(uuid.uuid4())
    run_id = run_id or f"{dag_status.dag_id}__{dag_status.timestamp.isoformat()}"
    
    # Construct the document to be stored
    dag_status_document = dag_status.dict()
    dag_status_document['id'] = document_id
    dag_status_document['run_id'] = run_id
    
    try:
        container.upsert_item(dag_status_document)
        return {"message": "DAG status stored successfully", "id": document_id}
    except exceptions.CosmosHttpResponseError as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get('/get_dag_status/{dag_id}')
def get_dag_status(dag_id: str):
    try:
        query = "SELECT * FROM c WHERE c.dag_id = @dag_id ORDER BY c.timestamp DESC"
        parameters = [{"name": "@dag_id", "value": dag_id}]
        items = list(container.query_items(
            query=query,
            parameters=parameters,
            enable_cross_partition_query=True
        ))
        if not items:
            raise HTTPException(status_code=404, detail="DAG status not found")
        # Return the most recent status
        return items[0]
    except exceptions.CosmosHttpResponseError as e:
        raise HTTPException(status_code=500, detail=str(e))

